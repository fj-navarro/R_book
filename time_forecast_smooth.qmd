# Forecasting with Exponential Smoothing

The **exponential smoothing functions** are one of the most popular forecasting approaches among the traditional time series forecasting models. This approach, conceptually, is close to the **moving average approach** we introduced previously, as both are based on forecasting the future values of the series by averaging the past observations of the series. The **main distinction** between the exponential smoothing and the moving average approaches is that the first is averaging all series observations, as opposed to a subset of $m$ observations by the latter. Furthermore, the advance exponential smoothing functions can handle series with a **trend and seasonal components**.

## Simple Exponential Smoothing Model

The **Simple exponential smoothing (SES)** is the simplest forecasting model among the exponential smoothing family. The main assumption of this model is that the series stays at the same level (that is, the local mean of the series is constant) over time, and therefore, this model is suitable for series with **neither trend nor seasonal components**.

The **main attribute** of the SES model is the weighted average technique, which is based on the exponential decay of the observation weights according to their chronological distance (that is, series index or timestamp) from the first forecasted values. The **decay rate** of the observation weights is set by \$\alpha, the smoothing parameter of the model.

The SES model shares some of the attributes of the **WMA model**, as both models forecast the future values of the series by a weighted average of the past observations of the series. The **main distinction** between the two is that the SES model is utilizing all the previous observations, whereas the WMA model is using only the most recent $m$ observations (for a model with a rolling window of a length of $m$).

The following **example** demonstrates the decay of the weights of the observations on the most recent 15 observations, for values between 0.01 to 1:

*Example:*

```{r}
alpha_df <- data.frame(index = seq(from = 1, to = 15, by = 1),
                       power = seq(from = 14, to = 0, by = -1))
alpha_df$alpha_0.01 <- 0.01 * (1 - 0.01) ^ alpha_df$power
alpha_df$alpha_0.2 <- 0.2 * (1 - 0.2) ^ alpha_df$power
alpha_df$alpha_0.4 <- 0.4 * (1 - 0.4) ^ alpha_df$power
alpha_df$alpha_0.6 <- 0.6 * (1 - 0.6) ^ alpha_df$power
alpha_df$alpha_0.8 <- 0.8 * (1 - 0.8) ^ alpha_df$power
alpha_df$alpha_1 <- 1 * (1 - 1) ^ alpha_df$power
```

Let's **plot the results**:

*Example:*

```{r message=FALSE}
library(plotly)
plot_ly(data = alpha_df) %>%
  add_lines(x = ~ index, y = ~ alpha_0.01, name = "alpha = 0.01") %>%
  add_lines(x = ~ index, y = ~ alpha_0.2, name = "alpha = 0.2") %>%
  add_lines(x = ~ index, y = ~ alpha_0.4, name = "alpha = 0.4") %>%
  add_lines(x = ~ index, y = ~ alpha_0.6, name = "alpha = 0.6") %>%
  add_lines(x = ~ index, y = ~ alpha_0.8, name = "alpha = 0.8") %>%
  add_lines(x = ~ index, y = ~ alpha_1, name = "alpha = 1") %>%
  layout(title = "Decay Rate of the SES Weights",
         xaxis = list(title = "Index"),
         yaxis = list(title = "Weight"))
```

### Forecasting with the `ses` Function

The **forecast package** provides a customized SES model with the `ses` function. The main **arguments** of this function are as follows:

-   `initial`: Defines the method for initializing the value of $\hat Y_1$ , which can be calculated by using the first few observations of the series by setting the argument to simple, or by estimating it with `ets` model (an advanced version of the Holt-Winters model from the forecast package) when setting it to optimal.

-   `alpha`: Defines the value of the smoothing parameter of the model. If set to `NULL`, the function will estimate it.

-   `h`: Sets the forecast horizon.

Let's use the `ses` function to forecast the monthly prices of the **Robusta coffee** data again. We will leave the last 12 months of the series as a testing set for benchmarking the model's performance. We will do this using the `ts_split` function from the TSstudio package:

*Example:*

```{r echo=FALSE}
# Create the Robusta dataset
library(TSstudio)
data(Coffee_Prices)
ts_info(Coffee_Prices)
# Extract the monthly prices of the Robusta coffee
robusta <- Coffee_Prices[,1]
```

```{r}
library (TSstudio)
robusta_par <- ts_split(robusta, sample.out = 12)
train <- robusta_par$train
test <- robusta_par$test
```

After we set the training and testing partition, we will use the **training partition** to train a SES model with the ses function:

*Example:*

```{r message=FALSE}
library(forecast)
fc_ses <- ses(train, h = 12, initial = "optimal")
# Review the model details
fc_ses$model
```

We can review the **model's performance** by using the `test_forecast` function:

*Example:*

```{r}
test_forecast(actual = robusta,
              forecast.obj = fc_ses,
              test = test) %>%
  layout(title = "Robusta Coffee Prices Forecast vs. Actual",
         xaxis = list(range = c(2010, max(time(robusta)))),
         yaxis = list(range = c(1, 3)))
```

As we can see from the preceding forecast plot, the `ses` function is utilizing the training set to identify the series level by estimating the **alpha parameter** and the initial level of the model (or $\hat Y_i$). The forecast value level is fairly close to the value of the last observation of the series since the value, in this case, is close to $1$. Since the goal of the SES model is to forecast the level of the series, the model won't capture any short-term oscillation.

In the case of a **flat forecast**, the confidence intervals of the model play a critical role, since the level of uncertainty is higher. Therefore, it will be useful to evaluate whether the forecast values are within the model confidence interval bounds. We will use the `plot_forecast` function from the TSstudio package to create an interactive plot for the `fs_ses` model we created and plot the **testing set**:

*Example:*

```{r}
plot_forecast(fc_ses) %>%
  add_lines(x = time(test) + deltat(test),
            y = as.numeric(test),
            name = "Testing Partition") %>%
  layout(title = "Robusta Coffee Prices Forecast vs. Actual",
         xaxis = list(range = c(2010, max(time(robusta)) +
                                  deltat(robusta))),
         yaxis = list(range = c(0, 4)))
```

As you can see from the preceding forecast plot, the testing set is within the range of the **80% confidence interval**.

### Model optimization with grid search

The `ses` function **optimizes the values of the model parameters** ($\alpha$ and $l_0$) that minimize the sum of squared errors (SSE) of the model on the training set. An alternative optimization approach is to use a **grid search**. A grid search is a powerful approach that's used to identify the values of the model's parameters that **minimize the model error**. In the case of the SES model, we will apply a grid search to identify the optimal value of that minimizes some error metric of the model (for example, MAPE, RMSE, and so on).

In the following example, we will use a **grid search** to tune the model parameters $\apha$ and $l_0$, which minimize the model's **MAPE** for the Robusta prices series. As we saw in the preceding performance plot of the Robusta forecast, there is a gap between the structure of the fitted values (marked in red) and the forecasted value (marked in green) since the SES model has a flat forecast. Therefore, we will split the model into **training, testing, and validation partitions**, and for each value of $\alpha$, we will apply the following steps:

1.  Train the SES model using the training partition and forecast the observations of the testing partition.

2.  Evaluate the performance of the model on both the training and testing partition.

3.  Append the training and testing partitions (in chronological order) and retrain the model on the new partition (training and testing) before forecasting the values of the validation partition.

4.  Evaluate the performance of the second model on the validation partition.

*Example:*

```{r}
# Set the training, testing, and validation partitions
robusta_par1 <- ts_split(robusta, sample.out = 24)
train1 <- robusta_par1$train
test1 <- ts_split(robusta_par1$test, sample.out = 12)$train
robusta_par2 <- ts_split(robusta, sample.out = 12)
train2 <- robusta_par2$train
valid <- robusta_par2$test
```

We will now use the `train1` and `test1` variables for **training and testing partition**, and `train2` for **retraining the model and validating** the results on the valid partition. The following alpha variable defines the search range. We will assign a sequence of values between $0$ and $1$ with an increment of $0.01$ using the `seq` function:

*Example:*

```{r}
alpha <- seq(from = 0, to = 1, by = 0.01)
```

Since the value of `alpha` must be greater than zero, we will replace $0$ with a small number that's fairly close to zero:

*Example:*

```{r}
alpha[1] <- 0.001
```

We will use the `lapply` function to iterate on the model using the different values of :

*Example:*

```{r message=FALSE}
library(dplyr)
ses_grid <- lapply(alpha, function(i){
  md1 <- md_accuracy1 <- md2 <- md_accuracy2 <- results <- NULL
  md1 <- ses(train1, h = 12, alpha = i, initial = "simple")
  md_accuracy1 <- accuracy(md1, test1)
  md2 <- ses(train2, h = 12, alpha = i, initial = "simple")
  md_accuracy2 <- accuracy(md2, valid)
  resutls <- data.frame(alpha = i,
                        train = md_accuracy1[9],
                        test = md_accuracy1[10],
                        valid = md_accuracy2[10])
  }) %>% 
  bind_rows()
```

As you can see in the following testing results, while $\alpha = 1$ minimizes the `MAPE` on the training partition, $\alpha=0.03$ minimizes the **error rate** on the testing partition. The results on the validation partition are following the same pattern as the testing partition, with an `MAPE` score of **9.98%** on the testing partition and **6.60%** on the validation partition:

*Example:*

```{r}
plot_ly(data = ses_grid, x = ~ alpha, y = ~ train,
        line = list(color = 'rgb(205, 12, 24)'),
        type = "scatter",
        mode = "lines",
        name = "Training") %>%
  add_lines(x = ~ alpha, y = ~ test, line = list(color = "rgb(22, 96,
                                                   167)", dash = "dash"),
              name= "Testing") %>%
  add_lines(x = ~ alpha, y = ~ valid, line = list(color = "green", dash = "dot"), name = "Validation") %>%
  layout(title = "SES Model Grid Search Results",
         yaxis = list(title = "MAPE (%)"))
```

## Holt method

The **Holt method**, also known as the **double exponential smoothing model**, is an expanded version of the SES model. It's based on estimating the most recent level and trend with the use of two smoothing parameters, $\alpha$ and $\beta$. Once the model estimates the most recent level and trend ($L_t$, and $T_t$, respectively), it utilizes them to construct the series forecast using the following equation:

-   For a series with **additive trend**, $\hat{Y}_{T+h} = L_T + hT_T$.

-   For a series with **multiplicative trend**, $\hat{Y}_{T+1} = L_T \times hT_T$.

The **forecast package** provides an implementation of the **Holt model** with the `holt` function. This function automatically initializes the values of $\hat L_1$ and $\hat T_1$, and identifies the values of $\alpha$ and $\beta$ that minimize the SSE of the model on the training set.

In the following example, we will retrieve the **US Gross Domestic Product (GDP)** quarterly data from the Federal Reserve Economic Data (FRED) API using the **Quandl package**:

*Example:*

```{r echo=FALSE}
# NASDAQ API: aqHhXcJKxo8AqdtDCykb
# FRED API: 2431902cfcc2e4ba038f04b68fcc0b13
library(fredr)
fredr_set_key("2431902cfcc2e4ba038f04b68fcc0b13")
library(TSstudio)
```

```{r}
gdp <- fredr(
  series_id = "GDP",
  observation_start = as.Date("2010-01-01"),
  observation_end = as.Date("2019-01-01")
  )
head(gdp)
# Convert df to ts
gdp_ts <- ts(data = gdp$value,
             start = c(2010, 1),
             frequency = 4
             )
str(gdp_ts)
ts_info(gdp_ts)
```

You will notice in the following plot that the **GDP series** has a strong linear trend and no seasonal component (since the series is seasonally adjusted): 

*Example:*

```{r}
ts_plot(gdp_ts,
        title = "US Gross Domestic Product",
        Ytitle = "Billions of Dollars",
        Xtitle = "Source: U.S. Bureau of Economic Analysis /fred.stlouisfed.org")
```

Like we did previously, we will leave the last **eight quarters for testing** and train the model with the rest of the observations of the series with the holt function:

*Example:*
```{r}
gdp_par <- ts_split(gdp_ts, sample.out = 8)
train <- gdp_par$train
test <- gdp_par$test
fc_holt <- holt(train, h = 8, initial = "optimal")
# Review the model's parameters
fc_holt$model
```

The initialized values of $\hat L_1$ and $\hat T_1$ of the function are relatively close to the values of the first observation of the series ($Y_1 = 14642.64$) and the average difference between each quarter. In addition, the selected $\alpha$ of $0.68$ indicated that the model heavily weighed the last observation of the series, $Y_t$. On the other hand, the value of $\beta$ is fairly close to zero, which indicates that updating the trend value from period to period doesn't take into account the change in the level and carries the initial value of the trend, $\hat{T_1}$, forward.

Let's **compare** the model's performance in the **training and testing** partitions with the `accuracy` function:

*Example:*

```{r}
accuracy(fc_holt, test)
```

As you can see from the output of the `accuracy` function, the ratio between  the error rate on the testing and training set is more than 6 times for the `RMSE` and 5.5 for the `MAPE`. This large ratio in the error metrics is mainly derived from the following two reasons:

-   The fitted values of the model on the training set are not bound by a linear line (as opposed to the forecast output).

-   The growth of the trend in the last few quarters shift from a linear rate of growth to an exponential rate.

The changes in the **trend growth and the forecast** can be observed with the `test_forecast` function:

*Example:*

```{r}
test_forecast(gdp_ts, forecast.obj = fc_holt, test = test)
```

While the **Holt model** was designed to handle time series with the linear trend, the exponential argument of the holt function provides the option to handle series with **exponential or decaying trends** when set to `TRUE`. 

*Example:*

```{r}
# Use the exponential argument to modify the growth pattern of the trend
# We seek a higher weight for the trend and we will set $\beta$ to 0.75
fc_holt_exp <- holt(train,
                    h = 8,
                    beta = 0.75,
                    initial = "optimal",
                    exponential = TRUE)
```

The **output** of this model is as follows:

*Example:*

```{r}
fc_holt_exp$model
```

We can review the **model's accuracy** on the **training and testing set** with the `accuracy` function:

*Example:*

```{r}
accuracy(fc_holt_exp, test)
```

Similarly, we can **plot the fitted and forecasted** values against the actual data with the test_forecast functions:

*Example:*

```{r}
test_forecast(gdp_ts, forecast.obj = fc_holt_exp, test = test)
```

As you can see, the **error rate** of the second Holt model is more balanced, where the ration between the error on the testing and training set is $2$ and $2.1$ for the `RMSE` and `MAPE` metrics, respectively.

## Holt-Winters model

The Holt-Winters model is the **most advanced model** among the exponential smoothing family of forecasting models. The Holt-Winters (HW) model is an extended version of the Holt model and can handle time series data with **both trend and seasonal components**. Forecasting the seasonal component requires a third smoother parameter and equation, in addition to the ones of the level and trend. 

Both of the trend and seasonal components could have either an **additive or multiplicity structure**, which adds some complexity to the model as there are multiple possible combinations:

-   Additive trend and seasonal components.

-   Additive trend and multiplicative seasonal components.

-   Multiplicative trend and additive seasonal components.

-   Multiplicative trend and seasonal component.

The most common implementation of the HW model in R is the `HoltWinters` and
`hw` functions from the **stats** and **forecast packages**. The main difference between the two functions is that the `hw` function can handle time series with an exponential or damped trend (similar to the Holt model). 

In the following example, we will use the `HoltWinters` function to forecast the last 12 months of the **USgas** series.

*Example:*

```{r}
# Diagnose the structure of the trend and seasonal components
data(USgas)
decompose(USgas) %>% plot()
```

We can observe from the preceding plot that both the trend and seasonal components of the series have an **additive structure**. Like we did previously, we will create training and testing partitions using the last 12 months of the series to **evaluate the performance** of the model:

*Example:*
```{r}
USgas_par <- ts_split(USgas, 12)
train <- USgas_par$train
test <- USgas_par$test
```

Next, we will use the `HoltWinters` model to forecast the last 12 months of the series (or the testing set):

*Example:*

```{r}
md_hw <- HoltWinters(train)
# Review the parameters of the trained model
md_hw
```

You will notice from the preceding model output that the model is mainly learning from the level and seasonal update (with $\alpha = 0.37$ and $\gamma = 0.44$ ). On the other hand, there is no learning from the trend initialized value $\beta = 0$. 

The next step is to forecast the next 12 months (or the values of the testing set) and evaluate the **model's performance** with the `accuracy` and `test_forecast` functions:

*Example:*

```{r}
fc_hw <- forecast(md_hw, h = 12)
accuracy(fc_hw, test)
```

The `accuracy` metrics of the model are **fairly balanced**, with an MAPE of 4.2% in the training set and 3.8% in the testing set. 

In the **plot** of the following model performance, you will notice that most of the **forecast errors** are related to the seasonal peak and the last observations of the series, which the model was underestimating:

*Example:*

```{r}
test_forecast(actual = USgas,
              forecast.obj = fc_hw,
              test = test)
```

Plotting the **fitted and forecasted** values provides us with a better understanding of the model's performance. As we can see in the preceding plot, the **HW model** is doing a good job of capturing both the series seasonal patterns. On the other hand, the model is missing the peak of the year during the month of January in most cases.

Note that **alternatively**, the model can be trained with a **grid search** in a similar manner to what we did with the SES model. In this case, there are three parameters to optimize: $\alpha$, $\beta$, and $\gamma$. The TSstudio package provides a customized grid search function based on the backtesting approach for training a `HoltWinters` function.