# Plyr & Dplyr

The **plyr package** works on **every type** of data structure, whereas the **dplyr package** is designed to work only on **dataframes**.

## Plyr

The most important utility of the **plyr package** is that a single line of code can perform all the `split()`, `apply()`, and `combine()` steps.

The steps for the **split-apply-combine** approach of data analysis are as follows:

1.  First, we split the dataset into some mutually exclusive groups.

2.  We then apply a task on each group and combine all the results to get the desired output.

3.  This group-wise task could be generating new variables, summarizing existing variables, or even performing regression analysis on each group.

4.  Finally, combining approaches helps us get a nice output to compare the results from different groups.

*Example:*

```{r}
library(plyr)
ddply(iris, .(Species), function(x) colMeans(x[-5]))
```

-   The first argument is the name of the data frame. We put iris, since the iris dataset is in the data frame structure, and we want to work on it.
-   The second argument is for a variable or variables, according to which we want to split our data frame. In this case, we have Species.
-   The third argument is a function that defines what kind of task we want to perform on each subset.

Note that the first letter of the function name specifies the input, and the second letter specifies the output type:

![Table 1: Types of funcctions in the plyr package](img/Picture1.png)

Note: `mapply()` can take multiple inputs as separate arguments, whereas a\*ply() takes only a single array argument.

## Dplyr

Quite often, in real-life situations, we start our analysis with a **data frame-type structure**. What do we do after getting a dataset and what are the basic data-manipulation tasks we usually perform before starting modeling?:

1.  Check the validity of a dataset based on conditions.

2.  Sort the dataset based on some variables, in ascending or descending order.

3.  Create new variables based on existing variables.

4.  Finally, summarize them.

**dplyr** can work with other data frame "backends" such as **SQL databases**. In fact, there is an SQL interface for relational databases via the DBI package

**dplyr** can also be integrated with the **data.table package** for large fast tables.

**IMPORTANT:** **Chaining (%\>%)** is a powerful feature of dplyr that allows the output from one verb to be piped into the input of another verb using a short, easy-to-read syntax.

### dplyr Grammar

All **dplyr functions** have a few common characteristics:

1.  The first argument is a dataframe.
2.  The subsequent arguments typically describe which columns to operate on using the variable names (without quotes).
3.  The output is a new datafram (dplyr doesn’t modify the existing original dataset because dplyr functions never modify their inputs).

**Dataframes** must be properly formatted and annotated for this to word. In particular, the data must be **tidy**, namely, there should be one observation per row, and each column should represent a feature or characteristic of that observation.

**dplyr’s verbs** are organized into four groups based on what they operate on: **rows, columns, groups, or tables**.

| Columns    | Rows                      |
|------------|---------------------------|
| `select()` | `filter()` (base: subset) |
| `rename()` | `arrange()`               |
| `mutate()` | `slice()`                 |

: Table 2. Dplyr functions

Because each **verb** does one thing well, solving complex problems will usually require **combining multiple verbs**, and we’ll do so with the **pipe**, `|>`. 

The **pipe** takes the thing on its left and passes it along to the function on its right so that `x |> f(y)` is equivalent to f(x, y), and `x |> f(y) |> g(z)` is equivalent to g(f(x, y), z). The easiest way to pronounce the pipe is **“then”**. 

### select()

Most of the time, we do not work on all the variables in a data frame. Selecting a few columns could make the analysis process less complicated.

The `select()` function can be used to select columns of a data frame that you want to focus on:

*Example:*

``` r
chicago <- readRDS("chicago.rds")
names(chicago)[1:3] 
select(chicago, c("city", "tmpd"))
select(chicago, c(1, 3))
subset <- select(chicago, city:dptp)
```

You can also omit variables using the `select()` function by using the negative sign. With select() you can do:

*Example 1:*

``` r
select(chicago, -(city:dptp))
subset <- select(chicago, ends_with("2"))
subset \<- select(chicago, starts_with("d"))
```

*Example 2:*

``` r
select(iris, Species, Sepal.Length, Sepal.Width)
```

### rename()

Renaming a variable in a data frame in R is surprisingly hard to do! The `rename()` function is designed to make this process easier:

*Example 1:*

``` r
names(chicago)[1:3] 
head(chicago[, 1:5], 3)
chicago <- rename(chicago, dewpoint = dptp, pm25 = pm25tmean2)
```

*Example 2:*

``` r
rename(iris, SL=Sepal.Length, SW= Sepal.Width, PL=Petal.Length, PW= Petal.Width )
```

The syntax inside the `rename()` function is to have the new name on the left-hand side of the = sign and the old name on the right-hand side.

### mutate()

The `mutate()` function exists to compute transformations of variables in a data frame. Very often, you want to create new variables that are derived from existing variables and `mutate()` provides a clean interface for doing that.

*Example 1:* Here we create a pm25detrend variable that subtracts the mean from the pm25 variable:

``` r
chicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))
```

*Example 2:*

``` r
mutate(iris, SLm=Sepal.Length/100, SWm= Sepal.Width/100, PLm=Petal. Length/100, PWm= Petal.Width/100 )
```

If we want to keep only the new variables and drop the old ones, we could use the `transmute()` function:

*Example:*

``` r
## Here we detrend the PM10 and ozone (O3) variables
transmute(chicago, pm10detrend = pm10tmean2 - mean(pm10tmean2, na.rm = TRUE), o3detrend = o3tmean2 - mean(o3tmean2, na.rm = TRUE)))
## Note that there are only two columns in the transmuted data frame
```

### filter()

The `filter()` function is used to extract **subsets of rows** from a dataframe. This function is similar to the existing `subset()`.

*Example:*

``` r
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80) 
summary(chic.f$pm25tmean2)
```
The **tidyverse** alternative writing:

``` R
# Flights with a departure dely higher than 120 mins
flights |> 
  filter(dep_delay > 120)
```

Sometimes, it is more important to subset the dataframe based on **values** of a variable or **multiple** variables.

*Example:*

``` r
filter(iris, Species=="virginica")
filter(iris, Species=="virginica" & Sepal.Length <6 & Sepal. Width <=2.7)
```
**Tidyverse:**

``` R
# Flights that departed on January 1
flights |> 
  filter(month == 1 & day == 1)
# Flights that departed in January or February
flights |> 
  filter(month == 1 | month == 2)
```

There’s a useful shortcut when you’re combining `|` and `==`: `%in%`. It keeps rows where the variable equals one of the values on the right:

``` R
flights |> 
  filter(month %in% c(1, 2))
```

### arrange()

The `arrange()` function is used to reorder rows of a data frame according to one of the variables/columns (while preserving corresponding order of other columns). To sort the whole data frame based on a single variable or multiple variables, we could use the `arrange()` function:

*Example 1:*

``` r
chicago <- arrange(chicago, date) 
chicago <- arrange(chicago, desc(date))
## Columns can be arranged in descending order
```

*Example 2:*

``` r
arrange(iris, Sepal.Length, desc(Sepal.Width))
```

### slice()

We could also extract the subset of a data frame using the `slice()` function:

*Example:*

``` r
slice(iris, 95:105)
```

### distinct()

Sometimes, we might encounter duplicate observations in a data frame. The `distinct()` function helps eliminates these observations:

*Example:*

``` r
distinct(iris, Species, Petal.Width)
```

### group_by() (base: aggregate() )

The `group_by()` function is used to generate summary statistics from the data frame within strata defined by a variable. In conjunction with the `group_by()` function we often use the `summarize()` function.

*Example 1:*

``` r
## create a year variable using as.POSIXlt()
chicago \<- mutate(chicago, year = as.POSIXlt(date)\$year + 1900)
## create a separate data frame that splits the original data frame by year
years \<- group_by(chicago, year)
## compute summary statistics for each year in the data frame 
summarize(years, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2, na.rm = TRUE), no2 = median(no2tmean2, na.rm = TRUE))
```

*Example 2:*

``` r
## Here, group_by() takes the data frame as an input and produces a data frame too. However, this data frame is a special type of data frame where grouping information is stored inside it
iris.grouped\<- group_by(iris, Species)
## When this special type of data frame (iris_grouped) is supplied as an input of the summarise() function, it knows that the calculation should be group- wise. Here, all the calculations using n(), mean() are performed group-wise
summarise(iris, meanSL=mean(Sepal.Length), meanSW=mean(Sepal.Width), meanPL=mean(Petal.Length), meanPW=mean(Petal.Width))
```

### Chaining (%\>%)

Sometimes, it could be necessary to use multiple functions to perform a single task. The pipeline operator %\>% is very handy for stringing together multiple dplyr functions in a sequence of operations.

This nesting is not a natural way to think about a sequence of operations:

``` r
third(second(first(x)))
```

The %\>% operator allows you to string operations in a left-to-right fashion:

``` r
first(x) %>% second(x) %>% third(x)
```

This way we don't have to create a set of temporary variables along the way or create a massive nested sequence of function calls.

Once you travel down the pipeline with %\>%, the first argument is taken to be the output of the previous element in the pipeline.
